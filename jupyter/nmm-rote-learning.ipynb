{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9254fb1c",
   "metadata": {},
   "source": [
    "# Rote Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1ebeccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link href='http://fonts.googleapis.com/css?family=Alegreya+Sans:100,300,400,500,700,800,900,100italic,300italic,400italic,500italic,700italic,800italic,900italic' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Arvo:400,700,400italic' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=PT+Mono' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Shadows+Into+Light' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Philosopher:400,700,400italic,700italic' rel='stylesheet' type='text/css'>\n",
       "\n",
       "<style>\n",
       "\n",
       "@font-face {\n",
       "    font-family: \"Computer Modern\";\n",
       "    src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
       "}\n",
       "\n",
       ".container { width: 100% }\n",
       "\n",
       "/* Formatting for header cells */\n",
       ".text_cell_render h1 {\n",
       "    font-family: 'Philosopher', sans-serif;\n",
       "    font-weight: 400;\n",
       "    font-size: 2.2em;\n",
       "    line-height: 100%;\n",
       "    color: rgb(0, 80, 120);\n",
       "    margin-bottom: 0.1em;\n",
       "    margin-top: 0.1em;\n",
       "    display: block;\n",
       "}\t\n",
       ".text_cell_render h2 {\n",
       "    font-family: 'Philosopher', serif;\n",
       "    font-weight: 400;\n",
       "    font-size: 1.9em;\n",
       "    line-height: 100%;\n",
       "    color: rgb(200,100,0);\n",
       "    margin-bottom: 0.1em;\n",
       "    margin-top: 0.1em;\n",
       "    display: block;\n",
       "}\t\n",
       "\n",
       ".text_cell_render h3 {\n",
       "    font-family: 'Philosopher', serif;\n",
       "    margin-top:12px;\n",
       "    margin-bottom: 3px;\n",
       "    font-style: italic;\n",
       "    color: rgb(94,127,192);\n",
       "}\n",
       "\n",
       ".text_cell_render h4 {\n",
       "    font-family: 'Philosopher', serif;\n",
       "}\n",
       "\n",
       ".text_cell_render h5 {\n",
       "    font-family: 'Alegreya Sans', sans-serif;\n",
       "    font-weight: 300;\n",
       "    font-size: 16pt;\n",
       "    color: grey;\n",
       "    font-style: italic;\n",
       "    margin-bottom: .1em;\n",
       "    margin-top: 0.1em;\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".text_cell_render h6 {\n",
       "    font-family: 'PT Mono', sans-serif;\n",
       "    font-weight: 300;\n",
       "    font-size: 10pt;\n",
       "    color: grey;\n",
       "    margin-bottom: 1px;\n",
       "    margin-top: 1px;\n",
       "}\n",
       "\n",
       ".text_cell_render em {\n",
       "    font-family: 'Philosopher', sans-serif;\n",
       "    color:        blue;\n",
       "    background-color: rgb(255,220,180);\n",
       "    font-size:    110%;\n",
       "    margin-left:   2px;\n",
       "    margin-right:  2px;\n",
       "    font-weight:   100;\n",
       "}\n",
       "\n",
       ".text_cell_render b {\n",
       "    color:            rgb(255,195,195);\n",
       "    background-color: rgb(0,0,0);\n",
       "    font-size:    110%;\n",
       "    margin-left:   2px;\n",
       "    margin-right:  2px;\n",
       "    font-weight:   650;\n",
       "}\n",
       "\n",
       ".text_cell_render u {\n",
       "    color:         red;\n",
       "    font-size:    120%;\n",
       "    margin-left:   2px;\n",
       "    margin-right:  2px;\n",
       "    font-weight:   650;\n",
       "}\n",
       "\n",
       ".text_cell_render tt {\n",
       "    font-size:    120%;\n",
       "    margin-left:   2px;\n",
       "    margin-right:  2px;\n",
       "    font-weight:   150;\n",
       "}\n",
       "\n",
       ".Codemirror {\n",
       "    font-family: \"PT Mono\";\n",
       "    font-size: 100%;\n",
       "}\n",
       "\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os.path\n",
    "css = \"\"\n",
    "if os.path.isfile(\"style.html\"):\n",
    "    from IPython.core.display import HTML\n",
    "    with open(\"style.html\", \"r\") as file:\n",
    "        css = file.read()\n",
    "HTML(css)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb5ad57",
   "metadata": {},
   "source": [
    "Der α-β-Pruning Algorithmus versucht durch die Auswertung der zukünftig möglichen Züge den Besten auszuwählen. Da der Suchraum jedoch zu groß ist um jedes mögliche Spiel zu betrachten, muss an einem bestimmten Punkt das Vorausschauen beendet werden und eine Schätzung statt dem tatsächlichen Wert verwendet werden. Diese Aufgabe übernimmt die in dem Notebook `nmm-heuristic` implementierte Heuristik.\n",
    "Dies bedeutet dass eine künstliche Intelligenz, die den α-β-Pruning Algorithmus implementiert, je besser ist, desto mehr Schritte in die die Zukunft geschaut werden kann. Die Laufzeit α-β-Pruning Algorithmus nimmt jedoch mit zunehmender Tiefe, aufgrund der sehr schnell ansteigenden Anzahl der Zustände, deutlich zu. Somit ist eine Neuberechnung der Schäzung bei jedem Zug nicht praktikabel.\n",
    "\n",
    "An diesem Punkt setzt das Rote-Learning an: Indem der α-β-Pruning Algorithmus um eine elementare Form des Lernens erweitert wird, wird dessen Effektivität stark gesteigert. Grundlegend werden bei der Verwendung von Rote-Learning alle Zustände, die jemals besucht wurden, zusammen mit den dazugehörigen errechneten Schätzungen abgespeichert. Anstatt die Wertschätzung dieser Zustände bei jedem Zug neu zu berechnen, können diese nun aus dem Speicher abgerufen werden. Dies spart vor allem bei einer hohen Suchtiefe viel Rechenzeit ein. Diese Einsparung der Rechenzeit kann darauf verwendet werden, weitere Zustände zu berechnen und somit die Qualität der Schätzungen zu erhöhen. Da mit jedem Spiel mehr Zustände und deren Schätzungen gespeichert werden, verbessert sich das Ergebnis des Algorithmus über Zeit. Es tritt also ein Lerneffekt ein."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a70dcf8",
   "metadata": {},
   "source": [
    "## Implementierung\n",
    "\n",
    "Um das oben genannte Prinzip von Rote-Learning in Python zu implementieren, wurde auf eine bereits fertige Implementierung des Alpha-Beta-Prunings Algorithmus für das Spiel Mühle zurück gegriffen. Dieser wurde im Rahmen der Studienarbeit entwickelt und musste für die Verwendung von Rote-Learning nur noch geringfügig angepasst werden. Um zu evaluieren ob Rote-Learning einen Vorteil gegenüber einem nicht trainierten Algorithmus herbeiführt, werden folgende Notebooks benötigt:\n",
    "\n",
    "- `nmm-cache` implementiert eine schnelle, persistierbare Transpositionstabelle (auch Cache genannt);\n",
    "- `nmm-rote-training` implementierung ein Klasse für den Trainingsteil des Rote-Learnings;\n",
    "- `nmm-alpha-beta-pruning` ist eine bereits vorhandene Implementierung des α-β-Pruning Algorithmus;\n",
    "- `nmm-tournament` ist eine ebenfalls bereits vorhandene Implementierung zur Evaluation, ob ein per Rote-Learning trainierter Algorithmus besser abschneidet als ein nicht trainierter Algorithmus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fde7d96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run ./nmm-cache.ipynb\n",
    "%run ./nmm-cache-rote-learning.ipynb\n",
    "%run ./nmm-rote-training.ipynb\n",
    "%run ./nmm-alpha-beta-pruning.ipynb\n",
    "%run ./nmm-tournament.ipynb\n",
    "%run ./nmm-alpha-beta-pruning-rote-learning.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b284b06",
   "metadata": {},
   "source": [
    "Desweitern wird das Paket `memory_profiler` eingebunden, welches die Überwachung der Auslastung des Arbeitsspeichers ermöglicht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30123f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from memory_profiler import memory_usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b2ea97",
   "metadata": {},
   "source": [
    "### Cache\n",
    "\n",
    "Um den bei Rote-Learning beschriebenen Lerneffekt zu erzielen und die Zustände zu Speichern, wurde eine Transpositionstabelle als Klasse `Cache` in dem Notebook `nmm-cache` implementiert. Diese Klasse verfügt über fünf Methoden zur Verwaltung des Caches:\n",
    "\n",
    "- `write` speichert einen neuen Zustand und die errechneten Werte ab;\n",
    "- `read` liest die gespeicherten Werte eines Zustandes aus dem Cache aus;\n",
    "- `save` legt den Inhalt des Caches in einer Datei auf einem Datenträger ab;\n",
    "- `load` lädt die Daten des Caches aus einer Datei auf dem Datenträger;\n",
    "- `clean` löscht Einträge aus dem Cache, falls die Anzahl der Einträge `max_size` überschritten wurde.\n",
    "\n",
    "Um die einzelnen Werte für die Zustände im Cache abzulegen, werden sowohl die Zustände als auch die Werte in ein Byte-Array konvertiert. Insgesamt ist ein Eintrag des Caches somit 32 Bytes groß. Um zu verhindern, dass der Cache zu groß wird um ihn im Arbeitsspeicher oder auf dem Datenträger speichern zu können, wurde der Parameter `max_size` eingeführt. Dieser begrenzt den Cache auf eine maximale Anzahl an Einträgen. Um die Performance zu steigern, wird dies jedoch nicht beim jedem Aufruf der `write` Methode geprüft sondern nur beim Aufruf der Methode `clean`. Dies kann dazu führen, dass zwischen den Aufrufen der `clean` Methode mehr Einträge im Cache vorhanden sind, als durch `max_size` erlaubt.\n",
    "Wird der Cache auf dem Datenträger abgelegt, entspricht die Dateigröße genau der Anzahl an Elementen multipliziert mit 32 Bytes. Die Größe das Caches im Arbeitsspeicher ist jedoch um einen Faktoren von ca. $6$ größer, da Python weiteren Arbeitsspeicher, beispielsweise für den Datentyp, reserviert.\n",
    "\n",
    "Der folgende Befehl erstellt einen Cache mit einer Größe von 50 Millionen Zuständen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71ea50a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cache = Cache(max_size = 50_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9936fbc",
   "metadata": {},
   "source": [
    "### Anbindung an α-β-Pruning\n",
    "\n",
    "Da im α-β-Pruning Algorithmus bereits die Verwendung eines In-Memory-Caches vorgesehen ist, mussten nur kleine Anpassungen vorgenommen werden. Es musste sichergestellt werden, dass sowohl zum Schreiben als auch zum Lesen der Werte aus dem Cache die richtigen Methoden aufgerufen werden, sowie dass ein Cache entweder als Parameter übergeben werden kann oder ein neuer instanziiert wird. Nach jeder Berechnung der nächsten besten Züge mit Hilfe der `bestMoves` Methode, wurde der Aufruf der `clean` Methode hinterlegt, um die Größe des Caches anzupassen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769198e6",
   "metadata": {},
   "source": [
    "###  Traingingsprozess\n",
    "\n",
    "Um die Transpositionstabelle zu trainieren und somit das Rote-Learning umzusetzen, wird die Klasse `Training` aus dem Notebook `nmm-rote-training` verwendet. Dazu muss zuerst eine Methode erstellt werden, welche den Algorithmus für die künstliche Intelligenz konfiguriert und generiert. Diese Methode wird `artificial_intelligence_generator` genannt und generiert eine AlphaBetaPruning Instanz, welche den übergebenen Cache und eine benutzerdefinierte Heuristiken verwendet. Die verwendeten Heuristiken wurden bereits im Rahmen der Studienarbeit ermittelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4767c155",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def artificial_intelligence_generator_primitiv(cache: Cache):\n",
    "    customWeights = HeuristicWeights(stones = 3, stash = 3, mills = 2, possible_mills = 1)\n",
    "    return AlphaBetaPruning(cache = cache, weights = customWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c5718ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def artificial_intelligence_generator_rote_learning(cache: Cache):\n",
    "    customWeights = HeuristicWeights(stones = 3, stash = 3, mills = 2, possible_mills = 1)\n",
    "    return AlphaBetaPruning(cache = cache, weights = customWeights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c965f77",
   "metadata": {},
   "source": [
    "Für den Cache wurde sich für eine maximale Größe von 50.000.000 Einträgen entschieden. Dies resultiert in eine maximal Größe des Caches von ca. 1,6Gb auf dem Datenträger. Des Weiteren werden die Standardwerte der Training-Klasse verwendet. Das heißt, dass ingesamt 100 Spiele gespielt werden und der Seed für den Zufallsgenerator nicht angepasst wird. Alle 10 Spiele wird der Cache auf dem Datenträger gespeichert und wird der Prefix `training-` für den Dateinamen verwendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9cdb645",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training = Training(\n",
    "    cache = cache, \n",
    "    artificial_intelligence = artificial_intelligence_generator_rote_learning,\n",
    "    path_prefix = 'training-rote-small-'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cbe0ba",
   "metadata": {},
   "source": [
    "Der Trainingsprozess wird durch den Aufruf der Funktion `train` gestartet und dauert mit der oben genannten Konfiguration in etwa 4,5 Stunden. Dabei werden bis zu 10 Gb Arbeitsspeicher benötigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fa5efa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0191dc1128184ea8bf42cd3ddddda154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training #training-rote-small-001:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "455f6da6dd32492782e3929d91aaa3a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Cache(size=17, max_size=50000000)\n",
      "\n",
      "Training #training-rote-small-002:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c240acf230734f34a7f56ebde2c510bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Cache(size=33, max_size=50000000)\n",
      "\n",
      "Training #training-rote-small-003:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e515d4634748cfa6e618aced22f1e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Cache(size=49, max_size=50000000)\n",
      "\n",
      "Training #training-rote-small-004:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "689c8bf05b0045a780cbde8922feb940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " > Cache(size=65, max_size=50000000)\n",
      "\n",
      "Training #training-rote-small-005:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56d60cf6c5f640628f8a157a7e76c9ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Cache(size=80, max_size=50000000)\n",
      "\n",
      "Training #training-rote-small-006:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8be79c0184304aef9cc6d5bcd607a76d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Cache(size=96, max_size=50000000)\n",
      "\n",
      "Training #training-rote-small-007:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a81f53294b5d4e3fbc8ed3bf051cc7bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Cache(size=112, max_size=50000000)\n",
      "\n",
      "Training #training-rote-small-008:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "312d3e7fbb0b4d9bae3dbcb53680ecc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Cache(size=128, max_size=50000000)\n",
      "\n",
      "Training #training-rote-small-009:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f48c923291e4ab7802b7db9136f5d68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Cache(size=143, max_size=50000000)\n",
      "\n",
      "Training #training-rote-small-010:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "187988d4160b41ef8d4f4d768a925b6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Cache(size=159, max_size=50000000)\n",
      "> Saving to 'training-rote-small-010.cache'...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e6096d34c2941c18b5e49b2733c923b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=159.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training #training-rote-small-011:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d310f11b80e4be0be44a1c388aff927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Cache(size=174, max_size=50000000)\n",
      "\n",
      "Training #training-rote-small-012:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04e863d344a84f259efe79e3e3de7665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Cache(size=189, max_size=50000000)\n",
      "\n",
      "Training #training-rote-small-013:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6bdfd6d2e2f42dbac712985704d712b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Cache(size=205, max_size=50000000)\n",
      "\n",
      "Training #training-rote-small-014:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1c254c636154176be0a27142740c6dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Cache(size=219, max_size=50000000)\n",
      "\n",
      "Training #training-rote-small-015:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d25ef5074f148de99cba4dfcebebaac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Cache(size=235, max_size=50000000)\n",
      "\n",
      "Training #training-rote-small-016:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05ce231536ab49afafffe5a76dae98fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " > Cache(size=251, max_size=50000000)\n",
      "\n",
      "Training #training-rote-small-017:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b442bab1c2c4201ba1459f2288d2c36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Cache(size=267, max_size=50000000)\n",
      "\n",
      "Training #training-rote-small-018:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b610e89f1ad4338b05092c2e761d011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Cache(size=283, max_size=50000000)\n",
      "\n",
      "Training #training-rote-small-019:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8afd4c98aeeb4563b2999de3f08326a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Cache(size=299, max_size=50000000)\n",
      "\n",
      "Training #training-rote-small-020:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5000eb0a8de44993ab5871de94005820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Cache(size=315, max_size=50000000)\n",
      "> Saving to 'training-rote-small-020.cache'...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18180cb0a86f43e484f19c3f812db7c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=315.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training #training-rote-small-021:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db3b81dbbb2c42ed8e41f800169e7bda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Cache(size=331, max_size=50000000)\n",
      "\n",
      "Training #training-rote-small-022:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb68c55131c94146bf94fbf49b01451b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Cache(size=346, max_size=50000000)\n",
      "\n",
      "Training #training-rote-small-023:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a6e0db06a924fff9a83416b79feaa1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mem_usage = memory_usage(training.train)\n",
    "print('Maximum memory usage: %s MB.' % max(mem_usage))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81852ffa",
   "metadata": {},
   "source": [
    "### Trainings Limitierungen\n",
    "\n",
    "Auf den ersten Blick scheint es so, dass man den Cache unendlich weiter trainieren kann. Dies jedoch mit der aktuellen Implementierung nicht zielführend. Ab einem gewissen Trainingszeitpunkt ist das Rekursionslimit der Einträge im Cache so hoch, dass dieses durch weiteres Training nicht erneut erreicht werden können. Dies ist lässt sich gut an nachfolgendem Beispiel erkennen:\n",
    "\n",
    "Durch die geringe Größe des Caches sowie dem kleinen Wert für `max_states` kommt man sehr schnell an den Punkt, an dem das Cache-Limit auf 3 erhöht wird. Dadurch werden fast alle Einträge aus dem Cache gelöscht und es verbleiben nur noch `48` im Cache. Dies passiert mehrere Male und ist ein Zeichen dafür, dass der Cache nicht mehr weiter trainiert werden kann, da dieser zu klein ist um genügend Einträge zu halten, damit mehr Einträge mit `limit = 3` berechnet werden können bevor der `max_states` Wert überschritten wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44af3d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Training(\n",
    "    cache                   = Cache(max_size = 1_000),\n",
    "    artificial_intelligence = lambda cache: AlphaBetaPruning(\n",
    "        cache      = cache,\n",
    "        max_states = 1_000\n",
    "    ),\n",
    "    path_prefix             = \"max-learning-\",\n",
    "    save_interval           = 1\n",
    ")\n",
    "#t.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e2414f",
   "metadata": {},
   "source": [
    "## Auswertung\n",
    "\n",
    "Bei der Auswertung wird auf die Klasse `Tournament` aus dem Notebook `nmm-tournament` zurück gegriffen. Diese Klasse besitzt die Methode `play`, welche es ermöglicht verschiedene Algorithmen gegeneinander Antreten zu lassen und die Ergebnisse zu speichern.\n",
    "\n",
    "Um zu ermitteln ob die Rote-Learning-Methode einen Vorteil gegenüber einem normalen Cache bietet, tritt eine über 100 Spiele trainierte Trainspositionstabelle gegen eine untrainierte Transpositionstabelle an. Dies wird zehn mal mit verschiedenen Seeds wiederholt. Das verändern der Seeds sorgt dabei für einen veränderten Spielverlauf.\n",
    "Somit sollte ermittelt werden können, ob durch das Training eine Verbesserung der künstlichen Intelligenz eintritt und wenn ja, wie deutlich diese Verbesserung ausfällt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bb0858",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    Tournament(\n",
    "        [\n",
    "            lambda: AlphaBetaPruning(\n",
    "                name='Primitiv',\n",
    "                weights = HeuristicWeights(stones = 3, stash = 3, mills = 2, possible_mills = 1),\n",
    "                cache = Cache(max_size = 50_000_000, path = 'training-small-final.cache')\n",
    "            ),\n",
    "            lambda: AlphaBetaPruning(\n",
    "                name='Rote Learning',\n",
    "                weights = HeuristicWeights(stones = 3, stash = 3, mills = 2, possible_mills = 1),\n",
    "                cache = Cache(max_size = 50_000_000, path = 'training-rote-small-final.cache')\n",
    "            )\n",
    "        ],\n",
    "        instances_per_round = 1,\n",
    "        seed_offset         = i,\n",
    "        name                = f\"small-full-{i}-seed\"\n",
    "    ).play()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a01609",
   "metadata": {},
   "source": [
    "Die Auswertung hat ergeben, dass von insgesamt von 20 gespielten Spielen 10 gewonnen wurden. Bei 5 lief es auf ein Unentschieden herraus und 5 wurden verloren. Damit lässt sich mit ziemlicher Sicherheit sagen, dass das Training der ersten Spielphase durch Rote-Learning einen Vorteil im gesamten Spielverlauf bietet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb1e7b3",
   "metadata": {},
   "source": [
    "## Fazit\n",
    "Das Ziel dieser Arbeit war die Implementierung des in dem Paper `Some Studies in Machine Learning Using the Game of Checkers` von `A.L.Samuel` beschriebene Prinzip von Rote-Learning zu erarbeiten. Das Ziel wurde erfolgreich durch eine Python-Implementierung erreicht und durch eine Verbesserung der Leistung einer künstlichen Intelligenz bestätigt. Im Laufe der Arbeit wurde sich neben der Implementierung in Python auch mit den dem α-β-Pruning Algorithmus sowie verschiedenen Methoden zur Persistierung eines Caches beschäftigt.\n",
    "\n",
    "Während in dem Paper jedoch zwei Methoden beschrieben werden, um Einträge aus einem zu großen Cache zu löschen, wird sich in dieser Arbeit nur auf eine Methode konzentriert. Im Paper wird zum einen die Aufruf-Frequenz oder zum anderen das Rekursionslimit des Eintrags. Diese Arbeit behandelt nur das Löschen von Einträgen basierend auf dem Rekursionslimit.\n",
    "\n",
    "Dennoch lässt sich sagen, dass diese Arbeit ein Erfolg war, da eine deutliche Verbesserung des α-β-Pruning mit einem trainierten Cache erreicht werden konnte, sodass nach  100 Trainingsrunden nur noch 25% der Spiele gegen eine nicht trainierte künstliche Intelligenz verloren wurden."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
