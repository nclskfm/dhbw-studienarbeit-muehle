{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9254fb1c",
   "metadata": {},
   "source": [
    "# Rote Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb5ad57",
   "metadata": {},
   "source": [
    "Die Implementierung des Alpha-Beta-Pruning Algorithmus basiert darauf, für alle möglichen zukünftigen Zustände zu ermitteln, wie wahrscheinlich es ist zu Gewinnen. Je mehr Züge dabei in die Tiefe geschaut werden kann, desto höher ist die Wahrscheinlichkeit, tatsächlich den besten Zug zu machen. Die Laufzeit zur Berechnung der Gewinn-Wahrscheinlichkeit nimmt mit zunehmender Tiefe, aufgrund der sehr schnell ansteigenden Anzahl der Zustände, deutlich zu. Somit ist eine Neuberechnung der Gewinn-Wahrscheinlichkeiten bei jedem Zug nur bis zu einer gewissen Tiefe praktikabel.\n",
    "\n",
    "An diesem Problem setzt Rote-Learning an, indem es den Alpha-Beta-Pruning Algorithmus um eine elementare Form des Lernens erweitert. Grundlegend werden bei der Verwendung von Rote-Learning alle Zustände, die jemals ausgerechnet wurden, zusammen mit den dazugehörigen errechneten Gewinn-Wahrscheinlichkeit abgespeichert. Anstatt die Wahrscheinlichkeiten dieser Zustände bei jedem Zug neu zu berechnen, können diese nun aus dem Speicher abgerufen werden. Dies spart vor allem bei einer hohen Tiefe einen großen Teil der Rechenzeit. Diese Einsparung der Rechenzeit kann darauf verwendet werden, Zustände, die sich weiter in der Tiefe befinden, zu berechnen. Da die gespeicherten Zustände mit jedem Spiel erweitert werden, verbessert sich das Ergebnis des Algorithmus über Zeit. Es tritt also ein Lern-Effekt ein."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a70dcf8",
   "metadata": {},
   "source": [
    "## Implementierung\n",
    "\n",
    "Um das oben genannte Prinzip von Rote-Learning in Python zu implementieren wurde auf eine Implementierung des Alpha-Beta-Prunings Algorithmus für das Spiel Mühle zurück gegriffen. Dieser wurde im Rahmen der Studienarbeit entwickelt und musste für die Verwendung von Rote-Learning nur noch geringfügig angepasst werden. Um zu evalieren ob Rote-Learning einen Vorteil bringt, werden folgende Notebooks benötigt:\n",
    "\n",
    "- `nmm-cache` - Implementierung eines persistenten Caches\n",
    "- `nmm-rote-training` - Implementierung einer Klasse zum trainieren des Caches\n",
    "- `nmm-alpha-beta-pruning` - Bereits vorhandene Implementierung des Alpha-Beta-Pruning Algorithmus\n",
    "- `nmm-tournament` - Bereits vorhandene Implementierung zur Evaluierung, welcher Algorithmus besser ist\n",
    "\n",
    "Desweitern wird noch das `memory_profiler` Packet eingebunden, mit welchem sich die Auslastung des Arbeitsspeichers überwachen lässt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fde7d96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from memory_profiler import memory_usage\n",
    "\n",
    "%run ./nmm-cache.ipynb\n",
    "%run ./nmm-rote-training.ipynb\n",
    "%run ./nmm-alpha-beta-pruning.ipynb\n",
    "%run ./nmm-tournament.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b2ea97",
   "metadata": {},
   "source": [
    "### Cache\n",
    "\n",
    "Um den bei Rote-Learning beschriebenen Lern-Effekt zu erzielen und die Zustände zu Speichern wurde eine `Cache` Klasse in dem Notebook `nmm-cache` implementiert. Diese Klasse verfügt über vier Methoden zur Verwaltung des Caches:\n",
    "- `write` - Speichert einen neuen Zustand im Cache ab\n",
    "- `read` - Liest die Werte eines Zustandes aus dem Cache aus\n",
    "- `save` - Speichert den Inhalt des Caches in einer Datei auf dem Datenträger ab\n",
    "- `load` - Lädt die Daten des Caches aus einer Datei auf dem Datenträger aus\n",
    "- `clean` - Löscht Einträge, wenn die Anzahl der Einträge `max_size` überschreitet\n",
    "\n",
    "Um die einzelnen Werte für die Zustände im Cache abzulegen werden sowohl die Zustände als auch die Werte in ein Byte-Array konvertiert. Insgesamt ist ein Eintrag des Caches somit 32 Bytes groß. Um zu verhindern, dass der Cache zu groß wird um ihn im Arbeitsspeicher oder auf dem Datenträger speichern zu können, wurde der Parameter `max_size` eingeführt. Dieser begrenzt den Cache auf eine maximale Anzahl an Einträgen. Um die Performance zu steigern, wird dies jedoch nicht beim jedem Aufruf der `write` Methode geprüft sondern nur beim Aufruf der Methode `clean`. Dies kann dazu führen, dass zwischen den Aufrufen der `clean` Methode mehr Einträge im Cache vorhanden sind, als durch `max_size` spezifiziert. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ea50a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cache = Cache(max_size = 50_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9936fbc",
   "metadata": {},
   "source": [
    "### Anbindung an Alpha-Beta-Pruning\n",
    "\n",
    "Da im Alpha-Beta-Pruning Algorithmus bereits die Verwendung eines In-Memrory-Caches vorgesehen ist, mussten nur geringe anpassungen vorgenommen werden. Es musste sichergestellt werden, dass sowohl zum schreiben als auch lesen des Caches die richtigen Methoden aufgerufen werden, sowie dass ein Cache entweder als Parameter übergeben werden kann oder ein neuer instanziiert wird. Nach jeder Berechnung der nächsten besten Züge mithilfe der `bestMoves` Methode wurde der Aufruf der `clean` Methode hinterlegt um die Größe des Caches anzupassen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6432135d",
   "metadata": {},
   "source": [
    "###  Traingings-Prozess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769198e6",
   "metadata": {},
   "source": [
    "Um die Transpositionstabelle zu trainieren, wird die Klasse `Training` aus dem Notebook `nmm-rote-training.ipynb`verwendet. Dazu muss zuerst eine Methode erstellt werden, welche den Algorithmus für die künstliche Intelligenz konfiguriert und generiert. Diese Methode wird `artificial_intelligence_generator` genannt und generiert einen Alpha-Beta-Pruning Algorithmus, welcher den übergebenen Cache und benutzerdefinierte Heuristiken verwendet. Die verwendeten Heuristiken wurden bereits im Rahmen der Studienarbeit ermittelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4767c155",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def artificial_intelligence_generator(cache: Cache):\n",
    "    customWeights = HeuristicWeights(stones = 3, stash = 3, mills = 2, possible_mills = 1)\n",
    "    return AlphaBetaPruning(cache = cache, weights = customWeights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c965f77",
   "metadata": {},
   "source": [
    "Für den Cache wurde sich (wie weiter oben zu sehen) für eine maximale Größe von 50 000 000 Einträgen entschieden. Dies resultiert in eine maximal Größe des Caches von 1,6Gb auf dem Datenträger. Des Weiteren werden die Standardwerte der Training-Klasse verwendet. Das heißt, dass ingesamt 100 Spiele gespielt werden und der Seed nicht angepasst wird. Alle 10 Spiele wird der Cache auf dem Datenträger gespeichert. Dazu wird der Prefix `training-` verwendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cdb645",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training = Training(\n",
    "    cache = cache, \n",
    "    artificial_intelligence = artificial_intelligence_generator,\n",
    "    path_prefix = 'training-small-'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cbe0ba",
   "metadata": {},
   "source": [
    "Der Trainings-Prozess wird durch den Aufruf der Methode `train` gestartet und dauert mit der oben genannten konfiguration in etwa 4,5 Stunden. Dabei werden 10 Gb Arbeitsspeicher benötigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fa5efa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# mem_usage = memory_usage(training.train)\n",
    "# print('Maximum memory usage: %s MB.' % max(mem_usage))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81852ffa",
   "metadata": {},
   "source": [
    "### Trainings Limitierungen\n",
    "Auch wenn es auf den ersten Blick so erscheint, dass man den Cache unendlich weiter trainieren kann, ist dies mit der aktuellen Implementierung nicht zielführend. Ab einem gewissen Punkt ist das Rekursionslimit der Einträge im Cache so hoch, dass dieses durch weiteres Training nicht erneut erreicht werden kann. Dies ist gut an dem nachfolgenden Beispiel zu sehen. Durch die geringe Größe des Caches sowie dem kleinen Wert für `max_states` kommt man sehr schnell an den Punkt, an dem das Cache-Limit auf 3 erhöht wird. Dadurch werden die meisten Einträge aus dem Cache gelöscht und es verbleiben nur noch `48` im Cache. Dies passiert mehrmals und ist ein Zeichen dafür, dass der Cache nicht mehr trainiert werden kann, da dieser zu klein ist um genügend Einträge zu halten damit man mehr Einträge mit `limit = 3` berechnen kann bevor der `max_states` Wert überschritten wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44af3d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = Training(\n",
    "#     cache                   = Cache(max_size = 1_000),\n",
    "#     artificial_intelligence = lambda cache: AlphaBetaPruning(\n",
    "#         cache      = cache,\n",
    "#         max_states = 1_000\n",
    "#     ),\n",
    "#     path_prefix             = \"max-learning-\",\n",
    "#     save_interval           = 1\n",
    "# )\n",
    "# t.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e2414f",
   "metadata": {},
   "source": [
    "## Auswertung\n",
    "\n",
    "Bei der Auswertung wird auf die Klasse `Tournament` aus dem Notebook `nmm-tournament` zurück gegriffen. Diese Klasse besitzt die Methode `play`, welche es ermöglicht verschiedene Algorithmen gegeneinander Antreten zu lassen und die Ergebnisse letzendlich auswertet.\n",
    "\n",
    "Um zu ermitteln ob die Rote-Learning-Methode einen Vorteil gegenüber einem normalen Cache bietet, tritt ein über 100 Spiele trainierter Cache gegen einen untrainierten Cache an. Dies wird zehn mal mit verschiedenen Seeds wiederholt. Das verändern der Seeds sorgt dabei für einen veränderten Spielverlauf.\n",
    "\n",
    "Somit sollte ermittelt werden können, ob durch das Training eine Verbesserung der künstlichen Intelligenz eintritt und wenn ja, wie deutlich diese Verbesserung ausfällt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bb0858",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    Tournament(\n",
    "        [\n",
    "            lambda: AlphaBetaPruning(\n",
    "                name='New Cache',\n",
    "                weights = HeuristicWeights(stones = 3, stash = 3, mills = 2, possible_mills = 1),\n",
    "                cache = Cache(max_size = 50_000_000)\n",
    "            ),\n",
    "            lambda: AlphaBetaPruning(\n",
    "                name='Trained Cache',\n",
    "                weights = HeuristicWeights(stones = 3, stash = 3, mills = 2, possible_mills = 1),\n",
    "                cache = Cache(max_size = 50_000_000, path = 'training-small-final.cache')\n",
    "            )\n",
    "        ],\n",
    "        instances_per_round = 1,\n",
    "        seed_offset         = i,\n",
    "        name                = f\"small-full-{i}-seed\"\n",
    "    ).play()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a01609",
   "metadata": {},
   "source": [
    "Die Auswertung hat ergeben, dass von insgesamt von 20 gespielten Spielen 10 gewonnen wurden. Bei 5 lief es auf ein Unentschieden herraus und 5 wurden verloren. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c35f71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
