{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9254fb1c",
   "metadata": {},
   "source": [
    "# Rote Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ebeccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "css = \"\"\n",
    "if os.path.isfile(\"style.html\"):\n",
    "    from IPython.core.display import HTML\n",
    "    with open(\"style.html\", \"r\") as file:\n",
    "        css = file.read()\n",
    "HTML(css)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb5ad57",
   "metadata": {},
   "source": [
    "Der α-β-Pruning Algorithmus versucht durch die Auswertung der zukünftig möglichen Züge den Besten auszuwählen. Da der Suchraum jedoch zu groß ist um jedes mögliche Spiel zu betrachten, muss an einem bestimmten Punkt das Vorausschauen beendet werden und eine Schätzung statt dem tatsächlichen Wert verwendet werden. Diese Aufgabe übernimmt die in dem Notebook `nmm-heuristic` implementierte Heuristik.\n",
    "Dies bedeutet dass eine künstliche Intelligenz, die den α-β-Pruning Algorithmus implementiert, je besser ist, desto mehr Schritte in die die Zukunft geschaut werden kann. Die Laufzeit α-β-Pruning Algorithmus nimmt jedoch mit zunehmender Tiefe, aufgrund der sehr schnell ansteigenden Anzahl der Zustände, deutlich zu. Somit ist eine Neuberechnung der Schäzung bei jedem Zug nicht praktikabel.\n",
    "\n",
    "An diesem Punkt setzt das Rote-Learning an: Indem der α-β-Pruning Algorithmus um eine elementare Form des Lernens erweitert wird, wird dessen Effektivität stark gesteigert. Grundlegend werden bei der Verwendung von Rote-Learning alle Zustände, die jemals besucht wurden, zusammen mit den dazugehörigen errechneten Schätzungen abgespeichert. Anstatt die Wertschätzung dieser Zustände bei jedem Zug neu zu berechnen, können diese nun aus dem Speicher abgerufen werden. Dies spart vor allem bei einer hohen Suchtiefe viel Rechenzeit ein. Diese Einsparung der Rechenzeit kann darauf verwendet werden, weitere Zustände zu berechnen und somit die Qualität der Schätzungen zu erhöhen. Da mit jedem Spiel mehr Zustände und deren Schätzungen gespeichert werden, verbessert sich das Ergebnis des Algorithmus über Zeit. Es tritt also ein Lerneffekt ein."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a70dcf8",
   "metadata": {},
   "source": [
    "## Implementierung\n",
    "\n",
    "Um das oben genannte Prinzip von Rote-Learning in Python zu implementieren, wurde auf eine bereits fertige Implementierung des Alpha-Beta-Prunings Algorithmus für das Spiel Mühle zurück gegriffen. Dieser wurde im Rahmen der Studienarbeit entwickelt und musste für die Verwendung von Rote-Learning nur noch geringfügig angepasst werden. Um zu evaluieren ob Rote-Learning einen Vorteil gegenüber einem nicht trainierten Algorithmus herbeiführt, werden folgende Notebooks benötigt:\n",
    "\n",
    "- `nmm-cache` implementiert eine schnelle, persistierbare Transpositionstabelle (auch Cache genannt);\n",
    "- `nmm-rote-training` implementierung ein Klasse für den Trainingsteil des Rote-Learnings;\n",
    "- `nmm-alpha-beta-pruning` ist eine bereits vorhandene Implementierung des α-β-Pruning Algorithmus;\n",
    "- `nmm-tournament` ist eine ebenfalls bereits vorhandene Implementierung zur Evaluation, ob ein per Rote-Learning trainierter Algorithmus besser abschneidet als ein nicht trainierter Algorithmus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fde7d96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run ./nmm-cache.ipynb\n",
    "%run ./nmm-rote-training.ipynb\n",
    "%run ./nmm-alpha-beta-pruning.ipynb\n",
    "%run ./nmm-tournament.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b284b06",
   "metadata": {},
   "source": [
    "Desweitern wird das Paket `memory_profiler` eingebunden, welches die Überwachung der Auslastung des Arbeitsspeichers ermöglicht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30123f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from memory_profiler import memory_usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b2ea97",
   "metadata": {},
   "source": [
    "### Cache\n",
    "\n",
    "Um den bei Rote-Learning beschriebenen Lerneffekt zu erzielen und die Zustände zu Speichern, wurde eine Transpositionstabelle als Klasse `Cache` in dem Notebook `nmm-cache` implementiert. Diese Klasse verfügt über vier Methoden zur Verwaltung des Caches:\n",
    "\n",
    "- `write` speichert einen neuen Zustand und die errechneten Werte ab;\n",
    "- `read` liest die gespeicherten Werte eines Zustandes aus dem Cache aus;\n",
    "- `save` legt den Inhalt des Caches in einer Datei auf einem Datenträger ab;\n",
    "- `load` lädt die Daten des Caches aus einer Datei auf dem Datenträger;\n",
    "- `clean` löscht Einträge aus dem Cache, falls die Anzahl der Einträge `max_size` überschritten wurde.\n",
    "\n",
    "Um die einzelnen Werte für die Zustände im Cache abzulegen, werden sowohl die Zustände als auch die Werte in ein Byte-Array konvertiert. Insgesamt ist ein Eintrag des Caches somit 32 Bytes groß. Um zu verhindern, dass der Cache zu groß wird um ihn im Arbeitsspeicher oder auf dem Datenträger speichern zu können, wurde der Parameter `max_size` eingeführt. Dieser begrenzt den Cache auf eine maximale Anzahl an Einträgen. Um die Performance zu steigern, wird dies jedoch nicht beim jedem Aufruf der `write` Methode geprüft sondern nur beim Aufruf der Methode `clean`. Dies kann dazu führen, dass zwischen den Aufrufen der `clean` Methode mehr Einträge im Cache vorhanden sind, als durch `max_size` erlaubt.\n",
    "Wird der Cache auf dem Datenträger abgelegt, entspricht die Dateigröße genau der Anzahl an Elementen multipliziert mit 32 Bytes. Die Größe das Caches im Arbeitsspeicher ist jedoch um einen Faktoren von ca. $6$ größer, da Python weiteren Arbeitsspeicher, beispielsweise für den Datentyp, reserviert.\n",
    "\n",
    "Der folgende Befehl erstellt einen Cache mit einer Größe von 50 Millionen Zuständen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ea50a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cache = Cache(max_size = 50_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9936fbc",
   "metadata": {},
   "source": [
    "### Anbindung an α-β-Pruning\n",
    "\n",
    "Da im α-β-Pruning Algorithmus bereits die Verwendung eines In-Memory-Caches vorgesehen ist, mussten nur kleine Anpassungen vorgenommen werden. Es musste sichergestellt werden, dass sowohl zum Schreiben als auch zum Lesen der Werte aus dem Cache die richtigen Methoden aufgerufen werden, sowie dass ein Cache entweder als Parameter übergeben werden kann oder ein neuer instanziiert wird. Nach jeder Berechnung der nächsten besten Züge mit Hilfe der `bestMoves` Methode, wurde der Aufruf der `clean` Methode hinterlegt, um die Größe des Caches anzupassen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769198e6",
   "metadata": {},
   "source": [
    "###  Traingingsprozess\n",
    "\n",
    "Um die Transpositionstabelle zu trainieren und somit das Rote-Learning umzusetzen, wird die Klasse `Training` aus dem Notebook `nmm-rote-training` verwendet. Dazu muss zuerst eine Methode erstellt werden, welche den Algorithmus für die künstliche Intelligenz konfiguriert und generiert. Diese Methode wird `artificial_intelligence_generator` genannt und generiert eine AlphaBetaPruning Instanz, welche den übergebenen Cache und eine benutzerdefinierte Heuristiken verwendet. Die verwendeten Heuristiken wurden bereits im Rahmen der Studienarbeit ermittelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4767c155",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def artificial_intelligence_generator(cache: Cache):\n",
    "    customWeights = HeuristicWeights(stones = 3, stash = 3, mills = 2, possible_mills = 1)\n",
    "    return AlphaBetaPruning(cache = cache, weights = customWeights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c965f77",
   "metadata": {},
   "source": [
    "Für den Cache wurde sich für eine maximale Größe von 50.000.000 Einträgen entschieden. Dies resultiert in eine maximal Größe des Caches von ca. 1,6Gb auf dem Datenträger. Des Weiteren werden die Standardwerte der Training-Klasse verwendet. Das heißt, dass ingesamt 100 Spiele gespielt werden und der Seed für den Zufallsgenerator nicht angepasst wird. Alle 10 Spiele wird der Cache auf dem Datenträger gespeichert und wird der Prefix `training-` für den Dateinamen verwendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cdb645",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training = Training(\n",
    "    cache = cache, \n",
    "    artificial_intelligence = artificial_intelligence_generator,\n",
    "    path_prefix = 'training-small-'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cbe0ba",
   "metadata": {},
   "source": [
    "Der Trainingsprozess wird durch den Aufruf der Funktion `train` gestartet und dauert mit der oben genannten Konfiguration in etwa 4,5 Stunden. Dabei werden bis zu 10 Gb Arbeitsspeicher benötigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fa5efa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mem_usage = memory_usage(training.train)\n",
    "print('Maximum memory usage: %s MB.' % max(mem_usage))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81852ffa",
   "metadata": {},
   "source": [
    "### Trainings Limitierungen\n",
    "\n",
    "Auf den ersten Blick scheint es so, dass man den Cache unendlich weiter trainieren kann. Dies jedoch mit der aktuellen Implementierung nicht zielführend. Ab einem gewissen Trainingszeitpunkt ist das Rekursionslimit der Einträge im Cache so hoch, dass dieses durch weiteres Training nicht erneut erreicht werden können. Dies ist lässt sich gut an nachfolgendem Beispiel erkennen:\n",
    "\n",
    "Durch die geringe Größe des Caches sowie dem kleinen Wert für `max_states` kommt man sehr schnell an den Punkt, an dem das Cache-Limit auf 3 erhöht wird. Dadurch werden die fast Einträge aus dem Cache gelöscht und es verbleiben nur noch `48` im Cache. Dies passiert mehrere Male und ist ein Zeichen dafür, dass der Cache nicht mehr weiter trainiert werden kann, da dieser zu klein ist um genügend Einträge zu halten, damit mehr Einträge mit `limit = 3` berechnet werden können bevor der `max_states` Wert überschritten wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44af3d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Training(\n",
    "    cache                   = Cache(max_size = 1_000),\n",
    "    artificial_intelligence = lambda cache: AlphaBetaPruning(\n",
    "        cache      = cache,\n",
    "        max_states = 1_000\n",
    "    ),\n",
    "    path_prefix             = \"max-learning-\",\n",
    "    save_interval           = 1\n",
    ")\n",
    "t.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e2414f",
   "metadata": {},
   "source": [
    "## Auswertung\n",
    "\n",
    "Bei der Auswertung wird auf die Klasse `Tournament` aus dem Notebook `nmm-tournament` zurück gegriffen. Diese Klasse besitzt die Methode `play`, welche es ermöglicht verschiedene Algorithmen gegeneinander Antreten zu lassen und die Ergebnisse zu speichern.\n",
    "\n",
    "Um zu ermitteln ob die Rote-Learning-Methode einen Vorteil gegenüber einem normalen Cache bietet, tritt eine über 100 Spiele trainierte Trainspositionstabelle gegen eine untrainierte Transpositionstabelle an. Dies wird zehn mal mit verschiedenen Seeds wiederholt. Das verändern der Seeds sorgt dabei für einen veränderten Spielverlauf.\n",
    "Somit sollte ermittelt werden können, ob durch das Training eine Verbesserung der künstlichen Intelligenz eintritt und wenn ja, wie deutlich diese Verbesserung ausfällt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bb0858",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    Tournament(\n",
    "        [\n",
    "            lambda: AlphaBetaPruning(\n",
    "                name='New Cache',\n",
    "                weights = HeuristicWeights(stones = 3, stash = 3, mills = 2, possible_mills = 1),\n",
    "                cache = Cache(max_size = 50_000_000)\n",
    "            ),\n",
    "            lambda: AlphaBetaPruning(\n",
    "                name='Trained Cache',\n",
    "                weights = HeuristicWeights(stones = 3, stash = 3, mills = 2, possible_mills = 1),\n",
    "                cache = Cache(max_size = 50_000_000, path = 'training-small-final.cache')\n",
    "            )\n",
    "        ],\n",
    "        instances_per_round = 1,\n",
    "        seed_offset         = i,\n",
    "        name                = f\"small-full-{i}-seed\"\n",
    "    ).play()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a01609",
   "metadata": {},
   "source": [
    "Die Auswertung hat ergeben, dass von insgesamt von 20 gespielten Spielen 10 gewonnen wurden. Bei 5 lief es auf ein Unentschieden herraus und 5 wurden verloren. Damit lässt sich mit ziemlicher Sicherheit sagen, dass das Training der ersten Spielphase durch Rote-Learning einen Vorteil im gesamten Spielverlauf bietet."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
