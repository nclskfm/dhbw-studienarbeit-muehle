{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9254fb1c",
   "metadata": {},
   "source": [
    "# Rote Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb5ad57",
   "metadata": {},
   "source": [
    "## Was ist Rote Learning?\n",
    "\n",
    "Die Implementierung des Alpha-Beta-Pruning Algorithmus basiert darauf, für alle möglichen zukünftigen Zustände zu ermitteln, wie wahrscheinlich es ist zu Gewinnen. Je mehr Züge dabei in die Tiefe geschaut werden kann, desto höher ist die Wahrscheinlichkeit, tatsächlich den besten Zug zu machen. Die Laufzeit zur Berechnung der Gewinn-Wahrscheinlichkeit nimmt mit zunehmender Tiefe, aufgrund der sehr schnell ansteigenden Anzahl der Zustände, deutlich zu. Somit ist eine Neuberechnung der Gewinn-Wahrscheinlichkeiten bei jedem Zug nur bis zu einer gewissen Tiefe praktikabel.\n",
    "\n",
    "An diesem Problem setzt Rote-Learning an, indem es den Alpha-Beta-Pruning Algorithmus um eine elementare Form des Lernens erweitert. Grundlegend werden bei der Verwendung von Rote-Learning alle Zustände, die jemals ausgerechnet wurden, zusammen mit den dazugehörigen errechneten Gewinn-Wahrscheinlichkeit abgespeichert. Anstatt die Wahrscheinlichkeiten dieser Zustände bei jedem Zug neu zu berechnen, können diese nun aus dem Speicher abgerufen werden. Dies spart vor allem bei einer hohen Tiefe einen großen Teil der Rechenzeit. Diese Einsparung der Rechenzeit kann darauf verwendet werden, Zustände, die sich weiter in der Tiefe befinden, zu berechnen. Da die gespeicherten Zustände mit jedem Spiel erweitert werden, verbessert sich das Ergebnis des Algorithmus über Zeit. Es tritt also ein Lern-Effekt ein."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a70dcf8",
   "metadata": {},
   "source": [
    "## Implementierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fde7d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from memory_profiler import memory_usage\n",
    "\n",
    "%run ./nmm-cache.ipynb\n",
    "%run ./nmm-rote-training.ipynb\n",
    "%run ./nmm-alpha-beta-pruning.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6432135d",
   "metadata": {},
   "source": [
    "###  Traingings-Prozess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769198e6",
   "metadata": {},
   "source": [
    "Um den Transpositionstabelle zu trainieren, wird die Klasse `Training` aus dem Notebook `nmm-rote-training.ipynb`verwendet. Dazu muss zuerst eine Methode erstellt werden, welche den Algorithmus für die künstliche Intelligenz konfiguriert und generiert. Diese Methode wird `artificial_intelligence_generator` genannt und generiert einen Alpha-Beta-Pruning Algorithmus, welcher den übergebenen Cache und benutzerdefinierte Heuristiken verwendet. Die verwendeten Heuristiken wurden bereits in der Hausarbeit `Retrograde Analysis` ermittelt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4767c155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def artificial_intelligence_generator(cache: Cache):\n",
    "    customWeights = HeuristicWeights(stones = 3, stash = 3, mills = 2, possible_mills = 1)\n",
    "    return AlphaBetaPruning(cache = cache, weights = customWeights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c965f77",
   "metadata": {},
   "source": [
    "Für den Cache wurde sich für eine maximale Größe von 100 000 000 Einträgen entschieden. Dies resultiert in eine maximal Größe des Caches von 3,3 Gb auf dem Datenträger. Desweiteren werden die Standard-Werte der Training-Klasse verwendet. Das heißt, dass ingesamt 100 Spiele gespielt werden und der Seed nicht angepasst wird. Alle 10 Spiele wird der Cache auf dem Datenträger gespeichert. Dazu wird der Prefix `training-` verwendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cdb645",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = Cache(max_size = 100_000_000)\n",
    "training = Training(\n",
    "    cache = cache, \n",
    "    artificial_intelligence = artificial_intelligence_generator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cbe0ba",
   "metadata": {},
   "source": [
    "Der Trainings-Prozess wird durch den Aufruf der Methode `train` gestartet und dauert mit der oben genannten konfiguration in etwa 4,5 Stunden. Dabei werden ... Arbeitsspeicher benötigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fa5efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_usage = memory_usage(training.train)\n",
    "print('Maximum memory usage: %s MB.' % max(mem_usage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4fa554",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
